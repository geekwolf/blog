<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Geekwolf's Blog]]></title>
  <link href="http://geekwolf.github.io/atom.xml" rel="self"/>
  <link href="http://geekwolf.github.io/"/>
  <updated>2014-03-17T15:21:02+08:00</updated>
  <id>http://geekwolf.github.io/</id>
  <author>
    <name><![CDATA[Geekwolf]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Innodb索引原理和B+树]]></title>
    <link href="http://geekwolf.github.io/blog/2014/03/17/innodbsuo-yin-yuan-li-he-b-plus-shu/"/>
    <updated>2014-03-17T14:45:35+08:00</updated>
    <id>http://geekwolf.github.io/blog/2014/03/17/innodbsuo-yin-yuan-li-he-b-plus-shu</id>
    <content type="html"><![CDATA[<h5>目录<br></h5>

<p><a href="#t1">一、innodb存储引擎索引概述</a><br>
<a href="#t2">二、理解B+树算法</a><br>
&emsp;&emsp;&emsp;<a href="#t3">(1) B+树的插入操作</a><br>
&emsp;&emsp;&emsp;<a href="#t4">(2) B+树的删除操作</a><br>
<a href="#t5">三、B+树索引介绍</a><br>
&emsp;&emsp;&emsp;<a href="#t6">(1) 聚集索引</a><br>
&emsp;&emsp;&emsp;<a href="#t7">(2) 辅助索引</a><br>
&emsp;&emsp;&emsp;<a href="#t8">(3) B+树索引的管理</a><br>
<a href="#t9">四、B+树索引的使用</a><br>
&emsp;&emsp;&emsp;<a href="#t10">(1) 什么时候使用B+索引</a><br>
&emsp;&emsp;&emsp;<a href="#t11">(2) 顺序读、随机读与预读取</a><br>
&emsp;&emsp;&emsp;<a href="#t12">(3) 辅助索引的优化</a><br>
&emsp;&emsp;&emsp;<a href="#t13">(4) 联合索引</a><br></p>

<h5><span id="t1">一、innodb存储引擎索引概述</span>：<br></h5>

<p>innodb存储引擎支持两种常见的索引：B+树索引和哈希索引。<br>
innodb支持哈希索引是自适应的，innodb会根据表的使用情况自动生成哈希索引。<br>
B+树索引就是传统意义上的索引，是关系型数据库中最常用最有效的索引。B+树是从最早的平衡二叉树演变而来，但是B+树不是一个二叉树。B+中的B不代表二叉(Binary),而是代表平衡(Balance)。<br></p>

<p><strong>注意</strong>：B+树索引并不能找到一个键值对应的具体行。b+树索引只能查到被查找数据行所在的页，然后数据库通过把页读入内存，再在内存中查找，最后得到结果。</p>

<h5><span id="t2">二、理解B+树算法</span></h5>

<p>B+树是为磁盘及其他存储辅助设备而设计一种平衡查找树（不是二叉树）。B+树中，所有记录的节点按大小顺序存放在同一层的叶节点中，各叶节点用指针进行连接。<br>
下面演示一个B+数结构，高度为2，每页可放4条记录，扇出(fan out)为5。从下图1可以看出，所有记录都在页节点中，并且为顺序存放，我们从最左边的叶节点开始遍历，可以得到所有键值的顺序排序：5、10、15、20、25、30、50、55、60、65、75、80、85、90.
<img src="http://www.ruzuojun.com/wp-content/uploads/2013/09/1.png" alt="" /></p>

<p><span id="t3">（1） B+树的插入操作</span>
B+树的插入必须保证插入后叶节点的记录依然排序。同时要考虑插入B+树的三种情况，每种情况都可能导致不同的插入算法。如下表所示：<br>
<img src="http://www.ruzuojun.com/wp-content/uploads/2013/09/a.png" alt="" /></p>

<!--more-->


<p>我们实例分析B+树的插入，在图1的B+树中，我们需要插入28这个值。因为Leaf Page和Index page都没有满，我们直接将记录插入叶节点就可以了。如下图2所示：</p>

<p><img src="http://www.ruzuojun.com/wp-content/uploads/2013/09/2.png" alt="" /><br>
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;图2  插入键值28<br>
下面我们再插入70这个值，这时Leaf Page已经满了，但是Index Page还没有满，符合上面的第二种情况。这时插入Leaf Page的情况为
50、55、60、65、70.我们根据中间的值60拆分叶节点，可得到下图3所示（双项链表指针依然存在，没有画出）
<img src="http://www.ruzuojun.com/wp-content/uploads/2013/09/3.png" alt="" /><br>
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;图3  插入键值70<br>
最后我们再插入95，这个Leaf Page和Index Page都满了，符合上面第三种情况。需要做2次拆分，如下图4所示：<br>
<img src="http://www.ruzuojun.com/wp-content/uploads/2013/09/4.png" alt="" /><br>
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;图4  插入键值95<br>
可以看到，不管怎么变化，B+树总会保持平衡。但是为了保持平衡，对于新插入的键值可能需要做大量的拆分页操作。B+树主要用于磁盘，拆分意味着磁盘的操作，应该在可能的情况下尽量减少页的拆分。因此，B+树提供了旋转功能。旋转发生在Leaf Page已经满了，但是左右兄弟节点没有满的情况下。这时B+树并不是急着做页的拆分，而是旋转。旋转结果如图5所示，可以看到旋转操作使B+树减少了一次页的拆分操作，高度仍然为2.<br>
<img src="http://www.ruzuojun.com/wp-content/uploads/2013/09/2-600x161.png" alt="" />
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;图5 B+树的旋转操作</p>

<p><span id="t4">(2) B+树的删除操作</span>
B+树使用填充因子来控制数的删除变化。填充因子可以设置的最小值为50%。B+树的删除操作同样保证删除后叶节点的记录依然排序。
根据填充因子的变化，B+树删除依然需要考虑三种情况，如下表所示：<br>
<img src="http://www.ruzuojun.com/wp-content/uploads/2013/09/b.png" alt="" /></p>

<p>根据图4的B+树，我们进行删除操作，首先删除键值为70的这条记录，该记录符合上表第一种情况，删除后如下图6所示：
<img src="http://www.ruzuojun.com/wp-content/uploads/2013/09/6.png" alt="" />
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;图6 删除键值70</p>

<p>接着我们删除键值为25的记录，这也是属于上表第一种情况，不同的是该值还是index page中的值。因此在删除Leaf Page中的25后，还需要将25的右兄弟节点28更新到Index Page中，如下图7所示（图中有两个笔误，红色为修正值）：<br>
<img src="http://www.ruzuojun.com/wp-content/uploads/2013/09/7.png" alt="" />
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;图7  删除键值28<br>
最后我们删除键值为60的记录。删除Leaf page键值为60的记录后，其填充因子小于50%。需要做合并操作。同样在删除Index page中相关记录后需要做Index Page的合并操作。</p>

<h5><span id="t5">三、B+树索引介绍</span></h5>

<p>B+树索引的本质是B+树在数据库中的实现。但是B+树索引有一个特点是高扇出性，因此在数据库中，B+树的高度一般在2到3层。也就是说查找某一键值的记录，最多只需要2到3次IO开销。按磁盘每秒100次IO来计算，查询时间只需0.0.2到0.03秒。<br>
数据库中B+树索引分为聚集索引（clustered index）和非聚集索引（secondary index）.这两种索引的共同点是内部都是B+树，高度都是平衡的，叶节点存放着所有数据。不同点是叶节点是否存放着一整行数据。</p>

<p><span id="t6">(1) 聚集索引</span><br>
Innodb存储引擎表是索引组织表，即表中数据按主键顺序存放。而聚集索引就是按每张表的主键构造一颗B+树。并且叶节点存放整张表的行记录数据。每张表只能有一个聚集索引（一个主键）。<br>
聚集索引的另一个好处是它对于主键的排序查找和范围的速度非常快。叶节点的数据就是我们要找的数据。</p>

<pre><code>主键排序查找：例如我们要找出最新的10条团购订单，由于B+树是双项链表，我们可以迅速找到最后一个页，并取出10条记录，我们用Explain进行分析：
12:41:32 tuangou&gt; explain select * from groupon_so order by id desc limit 10\G
id: 1
select_type: SIMPLE
    table: groupon_so
     type: index
     possible_keys: NULL
      key: PRIMARY
  key_len: 8
      ref: NULL
     rows: 10
    Extra: 

1 row in set (0.00 sec)

主键范围查找：如果要通过主键查找某一范围内的数据，通过叶节点的上层中间节点就能得到页的范围，之后直接读取数据页即可：
12:50:19 tuangou&gt; explain select * from groupon_so where id&gt;10000000 and id&lt;12000000\G
       id: 1
select_type: SIMPLE
    table: groupon_so
     type: range
     possible_keys: PRIMARY
      key: PRIMARY
  key_len: 8
      ref: NULL
     rows: 4301486
    Extra: Using where
1 row in set (0.00 sec)
</code></pre>

<p><span id="t7">(2) 辅助索引</span><br>
辅助索引（也称非聚集索引）。叶级别不包含行的全部数据，叶级别除了包含行的键值以外，每个索引行还包含了一个书签（bookmark），该书签告诉innodb存储引擎，哪里可以找到与索引对应的数据。<br>
辅助索引的存在并不影响数据再聚集索引中的组织，因此一个表可以有多个辅助索引。当通过辅助索引查找数据时，innodb会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键。然后再通过主键索引找到一行完整的数据。</p>

<p><span id="t8">(3) B+树索引的管理</span><br>
索引的创建和删除可以用两种方式。一种是alter table,另一种是create/drop index</p>

<pre><code>alter table 创建和删除索引的语法为：
ALTER [ONLINE | OFFLINE] [IGNORE] TABLE tbl_name
| ADD {INDEX|KEY} [index_name]
    [index_type] (index_col_name,…) [index_option] …

ALTER [ONLINE | OFFLINE] [IGNORE] TABLE tbl_name
| DROP PRIMARY KEY
| DROP {INDEX|KEY} index_name

create/drop index的语法为：
CREATE [ONLINE|OFFLINE] [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name
[index_type]
ON tbl_name (index_col_name,…)

DROP [ONLINE|OFFLINE] INDEX index_name ON tbl_name
</code></pre>

<p>MySQL索引注意的问题：对于MySQL索引的添加和删除操作，MySQL先是创建一张加好索引的临时表，然后把数据导入临时表，再删除原表，把临时表重命名为原表。<br>
Innodb存储引擎从Innodb Plugin版本开始，支持一种快速创建索引的方法（只限于辅助索引，主键索引仍需要建临时表）。首先对表加S锁，在创建的过程中不需要重建表，但是由于上了S锁，在创建索引的过程中只能进行查询操作，不能更新数据。<br></p>

<h5><span id="t9">四、B+树索引的使用</span></h5>

<p><span id="t10">(1).什么时候使用B+索引</span><br>
当查询表中很少一部分数据时，B+索引才有意义。对于性别，地区类型字段，他们取值范围很小，即低选择性。这时加B+索引是没有必要的。相反，某个字段取值范围很广，如姓名，几乎没有重复，即高选择性，则使用B+索引是比较合适的。因此。当访问高选择性字段并取出很少一部分数据时，该字段加B+索引是非常有效的。但是当取出的数据行占表中大部分数据时，数据库就不会使用B+索引了。<br></p>

<p>举例说明下，看下面这个团购订单表groupon_so的部分索引：<br></p>

<pre><code>    14:08:34 tuangou&gt; show index from groupon_so\G
*************************** 1. row ***************************
Table: groupon_so
Non_unique: 0
 Key_name: PRIMARY
 Seq_in_index: 1
 Column_name: id
 Collation: A
 Cardinality: 10088342
 Sub_part: NULL
   Packed: NULL
     Null: 
Index_type: BTREE
  Comment: 
Index_comment: 
*************************** 2. row ***************************
Table: groupon_so
Non_unique: 1
Key_name: idx_groupon_so_order_id
Seq_in_index: 1
Column_name: order_id
Collation: A
Cardinality: 10088342
Sub_part: NULL
   Packed: NULL
     Null: 
Index_type: BTREE
  Comment: 
Index_comment: 
*************************** 3. row ***************************
Table: groupon_so
Non_unique: 1
 Key_name: idx_groupon_so_order_code
 Seq_in_index: 1
 Column_name: order_code
 Collation: A
 Cardinality: 10088342
 Sub_part: NULL
   Packed: NULL
   Null: 
Index_type: BTREE
   Comment: 
Index_comment: 
*************************** 4. row ***************************
    Table: groupon_so
    Non_unique: 1
 Key_name: idx_groupon_so_end_user_id
 Seq_in_index: 1
 Column_name: end_user_id
 Collation: A
 Cardinality: 10088342
 Sub_part: NULL
   Packed: NULL
   Null: YES
Index_type: BTREE
   Comment: 
Index_comment: 
*************************** 5. row ***************************
Table: groupon_so
Non_unique: 1
Key_name: idx_groupon_so_groupon_id
Seq_in_index: 1
Column_name: groupon_id
Collation: A
Cardinality: 148357
Sub_part: NULL
Packed: NULL
  Null: 
Index_type: BTREE
   Comment: 
Index_comment:


其中有一个索引 idx_groupon_so_order_id,这个索引里面字段订单号的值都是不重复的，是高选择性的字段。
我们查找order_id为 99165590 的这条记录，执行计划如下：

14:31:50 tuangou&gt; explain select * from groupon_so where order_id=99165590\G
*************************** 1. row ***************************
       id: 1
    select_type: SIMPLE
    table: groupon_so
     type: ref
possible_keys: idx_groupon_so_order_id
      key: idx_groupon_so_order_id
  key_len: 8
      ref: const
     rows: 1
    Extra: 
1 row in set (0.00 sec)
可以看到使用了idx_groupon_so_order_id这个索引，符合高选择性，取少部分数据这个特性。


但是如果执行下面这条语句：
14:32:33 tuangou&gt; explain select * from groupon_so where order_id&gt;99165590\G
*************************** 1. row ***************************
       id: 1
    select_type: SIMPLE
    table: groupon_so
    type: ALL
possible_keys: idx_groupon_so_order_id
    key: NULL
key_len: NULL
    ref: NULL
   rows: 10092839
  Extra: Using where
1 row in set (0.00 sec)

可以看到possible_keys依然是idx_groupon_so_order_code，但是索引优化使用的索引keys显示的是NULL，因为虽然这个字段是高选择性的，但是我们取出了表中的大部分数据，索引没有用到索引。

14:34:11 tuangou&gt; select @a:=count(id) from groupon_so where order_id&gt;99165590;
+—————+
| @a:=count(id) |
+—————+
|       8684424 |
+—————+
1 row in set (2.48 sec)

14:34:26 tuangou&gt; select @a:=count(id) from groupon_so;
+—————+
| @a:=count(id) |
+—————+
|       9858135 |
+—————+
1 row in set (1.86 sec)

14:37:25 tuangou&gt; select 8684424/9858135;
+—————–+
| 8684424/9858135 |
+—————–+
|          0.8809 |
+—————–+
1 row in set (0.00 sec)
可以看到我们取出了表中88%的数据，索引没有用到索引。
</code></pre>

<p><span id="t11">(2)顺序读、随机读与预读取</span><br>
顺序读是指顺序的读取磁盘上的块，随机读是指访问的块是不连续的，需要磁盘的磁头不断移动。随机读的性能是远远低于顺序读的。<br>
在数据库中，顺序读根据索引的叶节点就能顺序的读取所需的行数据，这个顺序读只是逻辑的顺序读，在磁盘上可能还是随机读。随机读是指访问辅助索引叶节点不能完全得到结果，需要根据辅助索引页节点中的主键去寻找实际数据行。对于一些取表里很大部分数据的查询，正式因为读取是随机读，而随机读的性能会远低于顺序读。所以优化器才会选择全部扫描顺序读，而不使用索引。<br>
innodb存储引擎有两个预读取方法，随机预读取和线性预读取。随机预读取是指当一个区（共64个连续页）中有13个页在缓冲区中并被频繁访问时，innodb存储引擎会将这个区中剩余的页预读到缓冲区。线性预读取基于缓冲池中页的访问方式，而不是数量。如果一个区中有24个页被顺序访问了，则innodb会读取下一个区的所有页到缓冲区。但是innodb预读取经过测试后性能比较差，经过TPCC测试发现禁用预读取比启用预读取提高了10%的性能。在新版本innodb中，mysql禁用了随机预读取，仅保留了线性预读取，并且加入了innodb_read_ahead_threshold参数，当连续访问页超过该值时才启用预读取，默认值为56。</p>

<pre><code>15:02:16 tuangou&gt; show variables like ‘innodb_read_ahead_threshold%’;
+—————————–+——-+
| Variable_name               | Value |
+—————————–+——-+
| innodb_read_ahead_threshold | 56    |
+—————————–+——-+
1 row in set (0.00 sec)
</code></pre>

<p>3)<span id="t12">辅助索引的优化</span><br>
通过前面可知，辅助索引的页节点包含主键，但是辅助索引的叶节点并不包含完整的行数据信息，因此，innodb存储引擎总是会从辅助索引的叶节点判断是否能得到数据。让我们看一个例子：<br></p>

<pre><code>mysql&gt; create table t ( a int not null, b varchar(20), primary key(a),key(b));
Query OK, 0 rows affected (0.18 sec)

mysql&gt; insert into t select  1,’kangaroo’;
Query OK, 1 row affected (0.00 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql&gt; insert into t select  2,’dolphin’;
Query OK, 1 row affected (0.01 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql&gt; insert into t select  3,’dragon’;
Query OK, 1 row affected (0.01 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql&gt; insert into t select  4,’anteloge’;
Query OK, 1 row affected (0.01 sec)
Records: 1  Duplicates: 0  Warnings: 0

如果执行select * from t很多人认为应该是如下结果：
mysql&gt; select * from t order by a\G;
*************************** 1. row ***************************
a: 1
b: kangaroo
*************************** 2. row ***************************
a: 2
b: dolphin
*************************** 3. row ***************************
a: 3
b: dragon
*************************** 4. row ***************************
a: 4
b: anteloge

4 rows in set (0.00 sec)

但是实际执行结果确是：
mysql&gt; select * from t\G;
*************************** 1. row ***************************
a: 4
b: anteloge
*************************** 2. row **************************
a: 2
b: dolphin
*************************** 3. row ***************************
a: 3
b: dragon
*************************** 4. row ***************************
a: 1
b: kangaroo
4 rows in set (0.00 sec)

因为辅助索引包含了主键a的值，因此访问b列上的辅助索引就可以得到a的值，这样就可以得到表中所有的数据。我们看这条语句的执行计划：
mysql&gt; explain select * from t\G;
*************************** 1. row ***************************
id: 1
select_type: SIMPLE
table: t
type: index
possible_keys: NULL         
      key: b
  key_len: 23
      ref: NULL
     rows: 4
    Extra: Using index
1 row in set (0.00 sec)


可以看到优化器最终走的索引b,如果想对a列进行排序，则需要进行order by操作：
mysql&gt; explain select * from t order by a\G;
*************************** 1. row ***************************
id: 1
select_type: SIMPLE
    table: t
     type: index
possible_keys: NULL
      key: PRIMARY
  key_len: 4
      ref: NULL
     rows: 4
    Extra: NULL
1 row in set (0.00 sec)

mysql&gt; select * from t order by a\G;
*************************** 1. row ***************************
a: 1
b: kangaroo
*************************** 2. row ***************************
a: 2
b: dolphin
*************************** 3. row ***************************
a: 3
b: dragon
*************************** 4. row ***************************
a: 4
b: anteloge

或者使用主键强制得到结果：
mysql&gt; select * from t force index(PRIMARY)\G;
*************************** 1. row ***************************
a: 1
b: kangaroo
*************************** 2. row ***************************
a: 2
b: dolphin
*************************** 3. row ***************************
a: 3
b: dragon
*************************** 4. row ***************************
a: 4
b: anteloge

4 rows in set (0.00 sec)
</code></pre>

<p><span id="t13">(4)联合索引</span><br>
联合索引是指对表上的多个列做索引，联合索引的创建方法和之前的一样，如下：</p>

<pre><code>mysql&gt; alter table t add key idx_a_b(a,b);
Query OK, 0 rows affected (0.17 sec)
Records: 0  Duplicates: 0  Warnings: 0
</code></pre>

<p>联合索引还是一个B+树，不同的是联合索引键值的数量不是1，而是大于等于2.<br>
下面我们讨论一个两个整形列组成的联合索引，假定两个键值的名称分别为a和b，如下图8所示，每个节点上有两个键值，(1,1),(1,2),(2,1),(2,4),(3,1),(3,2), 数据按(a,b)顺序进行排列</p>

<p><img src="http://www.ruzuojun.com/wp-content/uploads/2013/09/8.png" alt="" /></p>

<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;图8  多个键值的B+树<br></p>

<p>因此，对于查询select * from t where a=xxx and b=xxx,显然可以使用(a,b)这个联合索引。对于单个a列查询 select * from t where a=xxx也是可以使用(a,b)这个索引。但是对于b列的查询select * from t where b=xxx是用不到这颗B+树索引。可以看到叶节点上b的值为1、2、1、4、1、2.显然不是排序的，因此b列的查询使用不到(a,b)索引。<br></p>

<p>联合索引的第二个好处，可以对第二键值进行排序。例如很多情况下我们需要查询某个用户的购物情况，并按照时间排序，取出最近3次的购买记录，这时使用联合索引可以避免多一次的排序操作。因为索引本身在叶节点中已经排序了。看下面示例:<br></p>

<pre><code>mysql&gt; create table buy_log(userid int unsigned not null, buy_date date);
Query OK, 0 rows affected (0.09 sec)

mysql&gt; insert into buy_log values(1,’2013-01-01′);
Query OK, 1 row affected (0.01 sec)

mysql&gt; insert into buy_log values(2,’2013-01-01′);
Query OK, 1 row affected (0.01 sec)

mysql&gt; insert into buy_log values(3,’2013-01-01′);
Query OK, 1 row affected (0.01 sec)

mysql&gt; insert into buy_log values(1,’2013-02-01′);
Query OK, 1 row affected (0.01 sec)

mysql&gt; insert into buy_log values(3,’2013-02-01′);
Query OK, 1 row affected (0.00 sec)

mysql&gt; insert into buy_log values(1,’2013-03-01′);
Query OK, 1 row affected (0.01 sec)

mysql&gt; insert into buy_log values(1,’2013-04-01′);
Query OK, 1 row affected (0.01 sec)

mysql&gt; alter table buy_log add key(userid);
Query OK, 0 rows affected (0.07 sec)
Records: 0  Duplicates: 0  Warnings: 0

mysql&gt; alter table buy_log add key(userid,buy_date);
Query OK, 0 rows affected (0.11 sec)
Records: 0  Duplicates: 0  Warnings: 0
上面我们建立了测试表和数据，建立了2个索引来比较。两个索引都包含了userid字段。如果只对于userid查询，优化器的选择是：

mysql&gt; explain select * from buy_log where userid=2\G;
*************************** 1. row ***************************
id: 1
select_type: SIMPLE
table: buy_log
     type: ref
possible_keys: userid,userid_2
      key: userid
  key_len: 4
      ref: const
     rows: 1
    Extra: NULL
1 row in set (0.00 sec)
可以看到possible_keys里面两个索引都可以使用，分别是单个的userid索引和userid,buy_date的联合索引。但是优化器最终选择的是userid，因为该叶节点包含单个键值，因此一个页存放的记录应该更多。

接下来看以下的查询，假定要取出userid=1最近的3次购买记录，分别使用单个索引和联合索引的区别：
mysql&gt; explain select * from buy_log where userid=1 order by buy_date desc limit 3\G;
*************************** 1. row ***************************
id: 1
select_type: SIMPLE
    table: buy_log
     type: ref
possible_keys: userid,userid_2
      key: userid_2
  key_len: 4
      ref: const
     rows: 4
    Extra: Using where; Using index
1 row in set (0.00 sec)

同样对于上述SQL，两个索引都可使用，但是查询优化器使用了userid和buy_date组成的联合索引userid_2.因为这个联合索引中buy_date已经排序好了，可以减少一次排序操作。

如果我们强制使用user_id单个索引，可以看到如下情况：
mysql&gt; explain select * from buy_log force index(userid) where userid=1 order by buy_date desc limit 3\G;
*************************** 1. row ***************************
id: 1
select_type: SIMPLE
table: buy_log
     type: ref
possible_keys: userid
      key: userid
  key_len: 4
      ref: const
     rows: 4
    Extra: Using where; Using filesort
1 row in set (0.00 sec)
在Extra这里可以看到Using filesort，Using filesort指排序，但不一定是在文件中完成。
</code></pre>

<blockquote><p> 本文出自<a href="http://www.ruzuojun.com">http://www.ruzuojun.com</a><br>
 参考资料《MySQL技术内幕Innodb存储引擎》</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Infobright数据仓库安装及参数优化]]></title>
    <link href="http://geekwolf.github.io/blog/2014/02/28/infobrightshu-ju-cang-ku-an-zhuang-ji-can-shu-you-hua/"/>
    <updated>2014-02-28T20:30:10+08:00</updated>
    <id>http://geekwolf.github.io/blog/2014/02/28/infobrightshu-ju-cang-ku-an-zhuang-ji-can-shu-you-hua</id>
    <content type="html"><![CDATA[<h5>一、认知Infobright数据仓库</h5>

<ol>
<li>Infobright是开源的DATA Warehouse，可以作为Mysql的存储引擎（BRIGHTHOUSE）使用，select查询与Mysql无区别</li>
<li>适用于基于Mysql架构下的OLAP，区分为ICE（社区版免费）和IEE（企业版商业授权）</li>
<li>千万级的查询性能比MyISAM、InnoDB等快5-60倍，且数据量很大时，查询性能基本在同一个数量级，适合聚合查询（SUM,COUNT，AVG，GROUP BY）</li>
<li>列式存储，无需建索引和分区，高压缩比40:1（官方数字）</li>
<li>ICE和IEE版本的区别和限制<br>
<a href="https://www.infobright.org/index.php/Learn-More/ICE_IEE_Comparison/">https://www.infobright.org/index.php/Learn-More/ICE_IEE_Comparison/</a></li>
</ol>


<h5>二、Infobright基本安装初始化</h5>

<pre><code> wget http://www.infobright.org/downloads/ice/infobright-4.0.7-0-x86_64-ice.rpm
 rpm -ivh infobright-4.0.7-0-x86_64-ice.rpm --prefix=/usr/local/

 A.初始化数据库：
 /usr/local/infobright/scripts/mysql_install_db --datadir=/data/data/ --basedir=/usr/local/infobright-4.0.7-x86_64/ --force
   安装之后会生成
  /etc/my-ib.cnf.inactive （主配置文件，下面两个暂不讨论）
</code></pre>

<!--more-->


<pre><code>  /etc/my-ib-master.cnf
  /etc/my-ib-slave.cnf
  /etc/rc.d/init.d/mysqld-ib（启动脚本）
  mv  /etc/my-ib.cnf.inactive /etc/my-ib.cnf
  修改/etc/rc.d/init.d/mysqld-ib /etc/my-ib.cnf  的datadir basedir参数到指定位置
  修改权限chown mysql.mysql /etc/my-ib*  /data/data /ibcache/cachedata

 B.修改warehouse引擎配置文件
  /data/data/brighthouse.ini

 C.参数优化
   CacheFolder = /ibcache/cachedata/
   ServerMainHeapSize = 28000
   ServerCompressedHeapSize = 4000
   LoaderMainHeapSize = 800
   ControlMessages = 3
   KNFolder = BH_RSI_Repository
   AllowMySQLQueryPath = 0
</code></pre>

<p><strong>注释：</strong><br>
CacheFolder 临时数据目录，用于缓存处理查询的中间结果集，与Datadir相异为宜，可用空间大于20G<br>
ServerMainHeapSize IB主线程内存，一般设置为物理内存一半；若可能尽量增加<br>
ServerCompressedHeapSize  服务进程的压缩堆栈空间，存放压缩数据<br>
LoaderMainHeapSize Bhloader数据导入缓冲区，随目标表的列数增加而调整，loader进程的堆栈空间，一般最大不超过800M<br>
ControlMessages  控制盒查询日志的信息量级别（1-3之间）<br>
KNFolder  知识网络目录，默认在datadir目录下<br>
AllowMySQLQueryPath  是否支持Mysql原生的SQL查询，支持修改为1，否则0<br>
启动infobright：service mysqld-ib start</p>

<p><strong>ICE版本导入数据方式：<br></strong>
BRIGHTHOUSE<br>
load data infile &lsquo;/data/data.txt&rsquo; into table t fields terminated by &lsquo; &rsquo;;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mysql分区管理]]></title>
    <link href="http://geekwolf.github.io/blog/2014/02/28/mysqlfen-qu-guan-li/"/>
    <updated>2014-02-28T16:06:25+08:00</updated>
    <id>http://geekwolf.github.io/blog/2014/02/28/mysqlfen-qu-guan-li</id>
    <content type="html"><![CDATA[<h5>初探：</h5>

<p>   很长时间没写博客了，这两天一直在学习Mysql分区，总结下:<br/>
  Mysql支持水平分区，并不支持垂直分区;<br/>
  <strong>水平分区</strong>：指将同一表中不同行的记录分配到不同的物理文件中；<br/>
  <strong>垂直分区</strong>：指将同一表中不同列的记录分配到不同的物理文件中；<br/>
  其中CSV、FEDORATED、MERGE等引擎不支持分区，MYISAM、InnoDB、NDB等引擎支持分区<br/></p>

<h5>目的：</h5>

<p>  将一个表或索引分解为多个更小、更可管理的部分，从逻辑上讲，只有一个表或者索引，但是物理上这个表或者索引可能由数十个物理分区组成；没个分区都是独立的对象，可以独自处理，也可以作为一个更大对象的一部分进行处理（如果分区表很大，亦可以将分区分配到不同的磁盘上去）；在执行查询的时候，优化器会根据分区定义过滤哪些没有我们需要数据的分区，这样查询就无须全表扫描所有分区，只查找包含需要数据的分区即可</p>

<h5>适用场景：</h5>

<p>1、表非常大以至于无法全部都放到内存，或者只在表的最后部分有热点数据，其他均为历史数据
2、分区表数据更容易维护（可独立对分区进行优化、检查、修复及批量删除大数据可以采用drop分区的形式等）
3、分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备
4、分区表可以避免某些特殊的瓶颈（ps: InnoDB的单个索引的互斥访问、ext3文件系统的inode锁竞争等）
5、可以备份和恢复独立的分区，非常适用于大数据集的场景</p>

<!--more-->


<h5>分区表限制：</h5>

<ol>
<li>单表最多支持1024个分区</li>
<li>MySQL5.1只能对数据表的整型列进行分区，或者数据列可以通过分区函数转化成整型列;MySQL5.5的RANGE LIST类型可以直接使用列进行分区</li>
<li>如果分区字段中有主键或唯一索引的列，那么所有的主键列和唯一索引列都必须包含进来</li>
<li>分区表无法使用外键约束</li>
<li>分区必须使用相同的Engine</li>
<li>对于MyISAM分区表，不能在使用LOAD INDEX INTO CACHE操作</li>
<li>对于MyISAM分区表，使用时会打开更多的文件描述符（单个分区是一个独立的文件）</li>
</ol>


<h5>分区策略：</h5>

<ol>
<li>全量扫描数据，不需要任何索引：通过where条件大概定位哪个分区，必须将查询所需要扫描的分区个数限制在很小的数量</li>
<li>建立分区索引，分离热点：如将明显的热点数据分离到一个分区，使其尽量缓存到内存中，这样就能充分使用索引和缓存</br>
<strong>注意</strong>：以上策略均以查询得到过滤，丢掉额外的分区，分区本身不产生额外的代价为准则】</li>
</ol>


<h5>分区表使用过程的坑坑：</h5>

<ol>
<li>NULL值会使分区过滤无效: <br/>
分表的表达式的值可以是NULL，第一个分区为特殊分区存放NULL或者非法值<br/>
如： PARTITION BY RANGE YEAR(order_date)进行分区，那么order_date为NULL或者非法值，记录存放在第一个分区:<br/>
WHERE order_date BETWEEN ‘2014-01-01’ AND ‘2014-01-31’查询时会检查两个分区：<br/>
第一个分区及1月份分区，避免第一分区数据过大时造成查询代价过高，可以使用：建立第一分区专门存放order_date为NULL和非法值记录
PARTITION p_nulls VALUES LESS THAN(0)<br/>
MySQL5.5以后可以才用一下语法解决问题：
PARTITION BY RANGE COLUMNS(order_date)</li>
</ol>


<p>2.分区列和索引列不匹配<br/>
   此种情况下查询无法进行分区过滤，分区失效除非查询中包含了可以过滤分区的条件</p>

<p>3.RANGE类型分区随着分区数量增加会对MYSQL额外增加查询分区定义列表（符合条件行在哪个分区）的压力，尽量限制适当的分区数量;key和hash类型分区不存在此问题</p>

<p>4.重组分区或者类似alter语句可能会造成很大的开销<br/>
   新建或者删除分区操作很快，重组分区或者类似ALTER语句操作会先创建一个临时的分区，将数据复制其中，然后在删除原分区</p>

<h5>分区表类型：</h5>

<p>1.RANGE分区：行数据基于属于一个给定连续区间的列值被放入分区<br/>
&emsp;MySQL5.5开始支持RANGE COLUMNS的分区（引入Columns分区解决了MySQL 5.5版本之前RANGE分区和LIST分区只支持整数分区，从而导致需要额外的函数计算得到整数或者通过额外的转换表来转换为整数再分区的问题。Columns分区可以细分为RANGE Columns分区和LIST Columns分区，RANGE Columns分区和LIST Columns分区都支持整数、日期时间、字符串三大数据类型）</p>

<p>2.LIST分区：类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择。<br>
&emsp;MySQL5.5开始支持RANGE COLUMNS的分区
3.HASH分区：根据用户自定义的表达式的返回值来进行分区，返回值不能为负数
4.KEY分区：根据MySQLS数据库提供的哈希函数来进行分区
【注：无论创建何种类型的分区，如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分】</p>

<h5>分区相关查询：</h5>

<pre><code>查看当前数据库是否支持分区
mysql&gt; show variables like '%partition%';
+---------------------------------------+-------+
| Variable_name | Value |
+---------------------------------------+-------+
| have_partitioning | YES |
| innodb_adaptive_hash_index_partitions | 1 |
+---------------------------------------+-------+
2 rows in set

查看创建分区表的CREATE语句

mysql&gt;show create table operation_log;

查看表是否为分区表(Create_options)
mysql&gt;show table status(当前库所有表状态)
mysql&gt;show table status from lockrank like '%operation_log%';(lockrank库operation_log表状态)
*************************** 1. row ***************************
Table: operation_log
Create Table: CREATE TABLE `operation_log` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `cid` mediumint(7) unsigned NOT NULL,
  `accountid` mediumint(8) NOT NULL DEFAULT '0' ,
  `flag` tinyint(1) unsigned NOT NULL DEFAULT '0',
  `addtime` int(11) unsigned NOT NULL,
  `device` tinyint(1) unsigned NOT NULL DEFAULT '1' ,
  PRIMARY KEY (`id`,`addtime`),
  KEY `idx_accountid_addtime` (`accountid`,`addtime`),
  KEY `idx_accountid_flag` (`accountid`,`flag`),
) ENGINE=InnoDB AUTO_INCREMENT=50951039 DEFAULT CHARSET=utf8 COMMENT='操作记录'
/*!50100 PARTITION BY RANGE (addtime)
(PARTITION `2013-05` VALUES LESS THAN (1370016000) ENGINE = InnoDB,
 PARTITION `2013-06` VALUES LESS THAN (1372608000) ENGINE = InnoDB,
 PARTITION `2013-07` VALUES LESS THAN (1375286400) ENGINE = InnoDB,
 PARTITION `2013-08` VALUES LESS THAN (1377964800) ENGINE = InnoDB,
 PARTITION `2013-09` VALUES LESS THAN (1380556800) ENGINE = InnoDB,
 PARTITION `2013-10` VALUES LESS THAN (1383235200) ENGINE = InnoDB,
 PARTITION `2013-11` VALUES LESS THAN (1385827200) ENGINE = InnoDB,
 PARTITION `2013-12` VALUES LESS THAN (1388505600) ENGINE = InnoDB,
 PARTITION `2014-01` VALUES LESS THAN (1391184000) ENGINE = InnoDB,
 PARTITION `2014-02` VALUES LESS THAN (1393603200) ENGINE = InnoDB,
 PARTITION `2014-03` VALUES LESS THAN (1396281600) ENGINE = InnoDB,
 PARTITION `2014-04` VALUES LESS THAN (1398873600) ENGINE = InnoDB,
 PARTITION `2014-05` VALUES LESS THAN (1401552000) ENGINE = InnoDB,
 PARTITION `2014-06` VALUES LESS THAN (1404144000) ENGINE = InnoDB,
 PARTITION `2014-07` VALUES LESS THAN (1406822400) ENGINE = InnoDB,
 PARTITION `2014-08` VALUES LESS THAN (1409500800) ENGINE = InnoDB,
 PARTITION `2014-09` VALUES LESS THAN MAXVALUE ENGINE = InnoDB) */
1 row in set (0.00 sec)

查看select如何使用分区
mysql&gt; explain partitions select id,accountid,cid,flag from operation_log where addtime="1369362524" \G ;
 *************************** 1. row ***************************
   id: 1
  select_type: SIMPLE
table: operation_log
   partitions: 2013-05
 type: ALL
possible_keys: NULL
  key: NULL
  key_len: NULL
  ref: NULL
 rows: 4384356
Extra: Using where
1 row in set (0.00 sec)
``
分区表元数据统计表：INFORMATION_SCHEMA.PARTITIONS
查看分区表operation_log的分区信息
mysql&gt; SELECT partition_name part, partition_expression expr, partition_description descr, table_rows FROM INFORMATION_SCHEMA.partitions WHERE TABLE_SCHEMA = schema() AND TABLE_NAME='operation_log';
+---------+---------+------------+------------+
| part| expr| descr | table_rows |
+---------+---------+------------+------------+
| 2013-05 | addtime | 1370016000 | 5999642 |
| 2013-06 | addtime | 1372608000 | 4579263 |
| 2013-07 | addtime | 1375286400 | 3223772 |
| 2013-08 | addtime | 1377964800 | 1995058 |
| 2013-09 | addtime | 1380556800 | 2497406 |
| 2013-10 | addtime | 1383235200 | 4106974 |
| 2013-11 | addtime | 1385827200 | 6209559 |
| 2013-12 | addtime | 1388505600 | 6415349 |
| 2014-01 | addtime | 1391184000 | 3953594 |
| 2014-02 | addtime | 1393603200 | 0 |
| 2014-03 | addtime | 1396281600 | 0 |
| 2014-04 | addtime | 1398873600 | 0 |
| 2014-05 | addtime | 1401552000 | 0 |
| 2014-06 | addtime | 1404144000 | 0 |
| 2014-07 | addtime | 1406822400 | 0 |
| 2014-08 | addtime | 1409500800 | 0 |
| 2014-09 | addtime | MAXVALUE | 0 |
+---------+---------+------------+------------+
17 rows in set (1.48 sec)
</code></pre>

<h5>创建分区操作</h5>

<pre><code>RANGE分区：
mysql&gt; CREATE TABLE `operation_log` (
 -&gt;  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
 -&gt; `cid` mediumint(7) unsigned NOT NULL,
 -&gt; `accountid` mediumint(8) NOT NULL DEFAULT '0' ,
 -&gt;  `flag` tinyint(1) unsigned NOT NULL DEFAULT '0',
 -&gt;  `addtime` int(11) unsigned NOT NULL,
 -&gt; `device` tinyint(1) unsigned NOT NULL DEFAULT '1' ,
 -&gt;  PRIMARY KEY (`id`,`addtime`),
 -&gt; KEY `idx_accountid_addtime` (`accountid`,`addtime`),
 -&gt;  KEY `idx_accountid_flag` (`accountid`,`flag`),
 -&gt;) ENGINE=InnoDB AUTO_INCREMENT=50951039 DEFAULT CHARSET=utf8 COMMENT='操作记录'
 -&gt;/*!50100 PARTITION BY RANGE (addtime)
 -&gt;(PARTITION `2013-05` VALUES LESS THAN (1370016000) ENGINE = InnoDB,
 -&gt; PARTITION `2013-06` VALUES LESS THAN (1372608000) ENGINE = InnoDB,
 -&gt; PARTITION `2013-07` VALUES LESS THAN (1375286400) ENGINE = InnoDB,
 -&gt; PARTITION `2013-08` VALUES LESS THAN (1377964800) ENGINE = InnoDB,
 -&gt; PARTITION `2013-09` VALUES LESS THAN MAXVALUE ENGINE = InnoDB) */；
1 row in set (0.00 sec)
（ LESS THAN MAXVALUE考虑到可能的最大值）

list分区
//这种方式失败
mysql&gt; CREATE TABLE IF NOT EXISTS `list_part` (
 -&gt;   `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '用户ID',
 -&gt;   `province_id` int(2) NOT NULL DEFAULT 0 COMMENT '省',
 -&gt;   `name` varchar(50) NOT NULL DEFAULT '' COMMENT '名称',
 -&gt;   `sex` int(1) NOT NULL DEFAULT '0' COMMENT '0为男，1为女',
 -&gt;   PRIMARY KEY (`id`)
 -&gt; ) ENGINE=INNODB  DEFAULT CHARSET=utf8 AUTO_INCREMENT=1
 -&gt; PARTITION BY LIST (province_id) (
 -&gt; PARTITION p0 VALUES IN (1,2,3,4,5,6,7,8),
 -&gt; PARTITION p1 VALUES IN (9,10,11,12,16,21),
 -&gt; PARTITION p2 VALUES IN (13,14,15,19),
 -&gt; PARTITION p3 VALUES IN (17,18,20,22,23,24)
 -&gt; );
ERROR 1503 (HY000): A PRIMARY KEY must include all columns in the table's partitioning function

//这种方式成功
mysql&gt; CREATE TABLE IF NOT EXISTS `list_part` (
 -&gt;   `id` int(11) NOT NULL  COMMENT '用户ID',
 -&gt;   `province_id` int(2) NOT NULL DEFAULT 0 COMMENT '省',
 -&gt;   `name` varchar(50) NOT NULL DEFAULT '' COMMENT '名称',
 -&gt;   `sex` int(1) NOT NULL DEFAULT '0' COMMENT '0为男，1为女'
 -&gt; ) ENGINE=INNODB  DEFAULT CHARSET=utf8
 -&gt; PARTITION BY LIST (province_id) (
 -&gt; PARTITION p0 VALUES IN (1,2,3,4,5,6,7,8),
 -&gt; PARTITION p1 VALUES IN (9,10,11,12,16,21),
 -&gt; PARTITION p2 VALUES IN (13,14,15,19),
 -&gt; PARTITION p3 VALUES IN (17,18,20,22,23,24)
 -&gt; );
Query OK, 0 rows affected (0.33 sec)
上面的这个创建list分区时，如果有主銉的话，分区时主键必须在其中，不然就会报错。如果我不用主键，分区就创建成功了，一般情况下，一个张表肯定会有一个主键，这算是一个分区的局限性


hash分区
mysql&gt; CREATE TABLE IF NOT EXISTS `hash_part` (
 -&gt;   `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '评论ID',
 -&gt;   `comment` varchar(1000) NOT NULL DEFAULT '' COMMENT '评论',
 -&gt;   `ip` varchar(25) NOT NULL DEFAULT '' COMMENT '来源IP',
 -&gt;   PRIMARY KEY (`id`)
 -&gt; ) ENGINE=INNODB  DEFAULT CHARSET=utf8 AUTO_INCREMENT=1
 -&gt; PARTITION BY HASH(id)
 -&gt; PARTITIONS 3;
Query OK, 0 rows affected (0.06 sec)

key分区 
mysql&gt; CREATE TABLE IF NOT EXISTS `key_part` (
 -&gt;   `news_id` int(11) NOT NULL  COMMENT '新闻ID',
 -&gt;   `content` varchar(1000) NOT NULL DEFAULT '' COMMENT '新闻内容',
 -&gt;   `u_id` varchar(25) NOT NULL DEFAULT '' COMMENT '来源IP',
 -&gt;   `create_time` DATE NOT NULL DEFAULT '0000-00-00 00:00:00' COMMENT '时间'
 -&gt; ) ENGINE=INNODB  DEFAULT CHARSET=utf8
 -&gt; PARTITION BY LINEAR HASH(YEAR(create_time))
 -&gt; PARTITIONS 3;
Query OK, 0 rows affected (0.07 sec)
</code></pre>

<p><strong>增加子分区操作：</strong></p>

<p>子分区是分区表中每个分区的再次分割，子分区既可以使用HASH希分区，也可以使用KEY分区。这 也被称为复合分区（composite partitioning）。</p>

<pre><code>1. 如果一个分区中创建了子分区，其他分区也要有子分区
2. 如果创建了了分区，每个分区中的子分区数必有相同
3. 同一分区内的子分区，名字不相同，不同分区内的子分区名子可以相同（5.1.50不适用）

 mysql&gt; CREATE TABLE IF NOT EXISTS `sub_part` (
 -&gt;   `news_id` int(11) NOT NULL  COMMENT '新闻ID',
 -&gt;   `content` varchar(1000) NOT NULL DEFAULT '' COMMENT '新闻内容',
 -&gt;   `u_id` int(11) NOT NULL DEFAULT 0s COMMENT '来源IP',
 -&gt;   `create_time` DATE NOT NULL DEFAULT '0000-00-00 00:00:00' COMMENT '时间'
 -&gt; ) ENGINE=INNODB  DEFAULT CHARSET=utf8
 -&gt; PARTITION BY RANGE(YEAR(create_time))
 -&gt; SUBPARTITION BY HASH(TO_DAYS(create_time))(
 -&gt; PARTITION p0 VALUES LESS THAN (1990)(SUBPARTITION s0,SUBPARTITION s1,SUBPARTITION s2),
 -&gt; PARTITION p1 VALUES LESS THAN (2000)(SUBPARTITION s3,SUBPARTITION s4,SUBPARTITION good),
 -&gt; PARTITION p2 VALUES LESS THAN MAXVALUE(SUBPARTITION tank0,SUBPARTITION tank1,SUBPARTITION tank3)
 -&gt; );
Query OK, 0 rows affected (0.07 sec)
</code></pre>

<p><strong>分区管理：</strong></p>

<pre><code>增加分区操作（针对设置MAXVALUE）
 range添加分区
mysql&gt;alter table operation_log add  partition(partition `2013-10` values less than (1383235200));  ---&gt;适用于没有设置MAXVALUE的分区添加
   ERROR 1481 (HY000):MAXVALUE can only be used in last partition definition
mysql&gt;alter table operation_log REORGANIZE partition `2013-09` into (partition `2013-09` values less than (1380556800),partition `2013-10` values less than (1383235200),partition `2013-11` values less than maxvalue);

 list添加分区
mysql&gt; alter table list_part add partition(partition p4 values in (25,26,28));
Query OK, 0 rows affected (0.01 sec)
Records: 0  Duplicates: 0  Warnings: 0

 hash重新分区
mysql&gt; alter table list_part add partition(partition p4 values in (25,26,28));
Query OK, 0 rows affected (0.01 sec)
Records: 0  Duplicates: 0  Warnings: 0

 key重新分区
mysql&gt; alter table key_part add partition partitions 4;
Query OK, 1 row affected (0.06 sec)//有数据也会被重新分配
Records: 1  Duplicates: 0  Warnings: 0

子分区添加新分区，虽然我没有指定子分区，但是系统会给子分区命名的
mysql&gt; alter table sub1_part add partition(partition p3 values less than MAXVALUE);
Query OK, 0 rows affected (0.02 sec)
Records: 0  Duplicates: 0  Warnings: 0
</code></pre>

<p><strong>删除分区操作</strong></p>

<pre><code>alter table user drop partition `2013-05`;
</code></pre>

<h5>分区表其他操作</h5>

<pre><code>重建分区(官方：与先drop所有记录然后reinsert是一样的效果；用于整理表碎片)
alter table operation_log rebuild partition `2014-01`;
重建多个分区
alter table operation_log rebuild partition `2014-01`,`2014-02`;
过程如下：

pro
优化分区（如果删除了一个分区的大量记录或者对一个分区的varchar blob text数据类型的字段做了许多更新，此时可以对分区进行优化以回收未使用的空间和整理分区数据文件）
alter table operation_log  optimize  partition `2014-01`;

优化的操作相当于check partition,analyze partition 和repair patition

分析分区
alter table operation_log  analyze partition  `2014-01`;

修复分区
alter table operation_log repair partition   `2014-01`;

检查分区
alter table operation_log check  partition   `2014-01`;
</code></pre>

<p><strong>注释：</strong></p>

<ol>
<li>mysqlcheck、myisamchk并不支持分区表，analyze,check,optimize,rebuild,repair,truncate不支持子分区操作</li>
<li>在MySQL5.6中，可以使用清空一个分区数据：alter table operation_log  truncate partition   <code>2014-01</code>;</li>
<li>清空该分区表所有分区数据：alter table operation_log  truncate partition   all;</li>
</ol>


<p><strong>参考文档：</strong></p>

<p><a href="http://blog.51yip.com/mysql/1013.html">http://blog.51yip.com/mysql/1013.html</a><br>
<a href="https://dev.mysql.com/doc/refman/5.6/en/partitioning-maintenance.html">https://dev.mysql.com/doc/refman/5.6/en/partitioning-maintenance.html</a><br>
<a href="http://dev.mysql.com/doc/refman/5.6/en/index.html">http://dev.mysql.com/doc/refman/5.6/en/index.html</a></p>
]]></content>
  </entry>
  
</feed>
